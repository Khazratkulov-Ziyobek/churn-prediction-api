"""
FastAPI ÑÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ñ‚Ð¾ÐºÐ° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð² Ð±Ð°Ð½ÐºÐ°.
ÐŸÑ€Ð¸Ð½Ð¸Ð¼Ð°ÐµÑ‚ JSON Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ñ‚Ð¾ÐºÐ° Ð¸ Ð±Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·.
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
import joblib
import numpy as np
import pandas as pd
import json
import os

# ============================================================
# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
# ============================================================
app = FastAPI(
    title="ðŸ¦ Bank Churn Prediction API",
    description="API-ÑÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚Ñ‚Ð¾ÐºÐ° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð±Ð°Ð½ÐºÐ°",
    version="1.0.0"
)

# ============================================================
# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð¾Ð²
# ============================================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODELS_DIR = os.path.join(BASE_DIR, "models")

model = joblib.load(os.path.join(MODELS_DIR, "best_model.pkl"))
scaler = joblib.load(os.path.join(MODELS_DIR, "scaler.pkl"))
le_gender = joblib.load(os.path.join(MODELS_DIR, "label_encoder_gender.pkl"))

with open(os.path.join(MODELS_DIR, "metadata.json"), "r", encoding="utf-8") as f:
    metadata = json.load(f)

feature_names = metadata["feature_names"]
needs_scaling = metadata.get("needs_scaling", False)


# ============================================================
# Pydantic Ð¼Ð¾Ð´ÐµÐ»Ð¸
# ============================================================
class ClientData(BaseModel):
    """Ð’Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ."""
    ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð½Ñ‹Ð¹_Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³: float = Field(..., ge=300, le=900, description="ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³ (300-900)")
    Ð³Ð¾Ñ€Ð¾Ð´: str = Field(..., description="Ð“Ð¾Ñ€Ð¾Ð´: ÐÐ»Ð¼Ð°Ñ‚Ñ‹, ÐÑÑ‚Ð°Ð½Ð° Ð¸Ð»Ð¸ ÐÑ‚Ñ‹Ñ€Ð°Ñƒ")
    Ð¿Ð¾Ð»: str = Field(..., description="ÐŸÐ¾Ð»: Male Ð¸Ð»Ð¸ Female")
    Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚: float = Field(..., ge=18, le=100, description="Ð’Ð¾Ð·Ñ€Ð°ÑÑ‚ (18-100)")
    ÑÑ‚Ð°Ð¶_Ð²_Ð±Ð°Ð½ÐºÐµ: float = Field(..., ge=0, le=20, description="Ð¡Ñ‚Ð°Ð¶ Ð² Ð±Ð°Ð½ÐºÐµ (Ð»ÐµÑ‚)")
    Ð±Ð°Ð»Ð°Ð½Ñ_Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð°: float = Field(0.0, ge=0, description="Ð‘Ð°Ð»Ð°Ð½Ñ Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð°")
    Ñ‡Ð¸ÑÐ»Ð¾_Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²: float = Field(..., ge=1, le=4, description="Ð§Ð¸ÑÐ»Ð¾ Ð±Ð°Ð½ÐºÐ¾Ð²ÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²")
    ÐµÑÑ‚ÑŒ_ÐºÑ€ÐµÐ´Ð¸Ñ‚ÐºÐ°: float = Field(..., ge=0, le=1, description="Ð•ÑÑ‚ÑŒ ÐºÑ€ÐµÐ´Ð¸Ñ‚ÐºÐ° (0 Ð¸Ð»Ð¸ 1)")
    Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹_ÐºÐ»Ð¸ÐµÐ½Ñ‚: float = Field(..., ge=0, le=1, description="ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚ (0 Ð¸Ð»Ð¸ 1)")
    Ð¾Ñ†ÐµÐ½Ð¾Ñ‡Ð½Ð°Ñ_Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°: float = Field(..., ge=0, description="ÐžÑ†ÐµÐ½Ð¾Ñ‡Ð½Ð°Ñ Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°")

    class Config:
        json_schema_extra = {
            "example": {
                "ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð½Ñ‹Ð¹_Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³": 650,
                "Ð³Ð¾Ñ€Ð¾Ð´": "ÐÐ»Ð¼Ð°Ñ‚Ñ‹",
                "Ð¿Ð¾Ð»": "Male",
                "Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚": 35,
                "ÑÑ‚Ð°Ð¶_Ð²_Ð±Ð°Ð½ÐºÐµ": 5,
                "Ð±Ð°Ð»Ð°Ð½Ñ_Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð°": 100000.0,
                "Ñ‡Ð¸ÑÐ»Ð¾_Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²": 2,
                "ÐµÑÑ‚ÑŒ_ÐºÑ€ÐµÐ´Ð¸Ñ‚ÐºÐ°": 1,
                "Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹_ÐºÐ»Ð¸ÐµÐ½Ñ‚": 1,
                "Ð¾Ñ†ÐµÐ½Ð¾Ñ‡Ð½Ð°Ñ_Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°": 120000.0
            }
        }


class PredictionResponse(BaseModel):
    """ÐžÑ‚Ð²ÐµÑ‚ ÑÐµÑ€Ð²Ð¸ÑÐ° Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸ÐµÐ¼."""
    probability: float = Field(..., description="Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ñ‚Ð¾ÐºÐ° (0-1)")
    prediction: int = Field(..., description="Ð‘Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· (0 â€” Ð¾ÑÑ‚Ð°Ð»ÑÑ, 1 â€” ÑƒÑˆÑ‘Ð»)")
    risk_level: str = Field(..., description="Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ñ€Ð¸ÑÐºÐ°: ÐÐ¸Ð·ÐºÐ¸Ð¹ / Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ / Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹")


# ============================================================
# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
# ============================================================
def preprocess_client(data: ClientData) -> np.ndarray:
    """ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸."""
    gender_encoded = le_gender.transform([data.Ð¿Ð¾Ð»])[0]

    cities = metadata["cities"]  # ['ÐÐ»Ð¼Ð°Ñ‚Ñ‹', 'ÐÑÑ‚Ð°Ð½Ð°', 'ÐÑ‚Ñ‹Ñ€Ð°Ñƒ']
    city_encoded = [1 if c == data.Ð³Ð¾Ñ€Ð¾Ð´ else 0 for c in cities]

    features = [
        data.ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð½Ñ‹Ð¹_Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³,
        gender_encoded,
        data.Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚,
        data.ÑÑ‚Ð°Ð¶_Ð²_Ð±Ð°Ð½ÐºÐµ,
        data.Ð±Ð°Ð»Ð°Ð½Ñ_Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð°,
        data.Ñ‡Ð¸ÑÐ»Ð¾_Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²,
        data.ÐµÑÑ‚ÑŒ_ÐºÑ€ÐµÐ´Ð¸Ñ‚ÐºÐ°,
        data.Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹_ÐºÐ»Ð¸ÐµÐ½Ñ‚,
        data.Ð¾Ñ†ÐµÐ½Ð¾Ñ‡Ð½Ð°Ñ_Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°,
    ] + city_encoded

    features_array = np.array(features).reshape(1, -1)

    # ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾ (Ð´Ð»Ñ LR)
    if needs_scaling:
        features_array = scaler.transform(features_array)

    return features_array


# ============================================================
# Ð­Ð½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚Ñ‹
# ============================================================
@app.get("/", tags=["Info"])
def root():
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ð°."""
    return {
        "service": "Bank Churn Prediction API",
        "version": "1.0.0",
        "model": metadata["best_model_name"],
        "metrics": metadata["metrics"],
        "endpoints": {
            "POST /predict": "ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð¾Ñ‚Ñ‚Ð¾ÐºÐ°",
            "GET /health": "ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ",
            "GET /docs": "Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ API (Swagger)"
        }
    }


@app.get("/health", tags=["Health"])
def health_check():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€Ð°Ð±Ð¾Ñ‚Ð¾ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ ÑÐµÑ€Ð²Ð¸ÑÐ°."""
    return {"status": "ok", "model_loaded": model is not None}


@app.post("/predict", response_model=PredictionResponse, tags=["Prediction"])
def predict(client: ClientData):
    """
    ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚Ñ‚Ð¾ÐºÐ° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°.

    ÐŸÑ€Ð¸Ð½Ð¸Ð¼Ð°ÐµÑ‚ JSON Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - probability: Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ñ‚Ð¾ÐºÐ° (float, 0-1)
    - prediction: Ð±Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· (0 Ð¸Ð»Ð¸ 1)
    - risk_level: ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ñ€Ð¸ÑÐºÐ°
    """
    try:
        if client.Ð³Ð¾Ñ€Ð¾Ð´ not in metadata["cities"]:
            raise HTTPException(
                status_code=400,
                detail=f"Ð“Ð¾Ñ€Ð¾Ð´ '{client.Ð³Ð¾Ñ€Ð¾Ð´}' Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ. Ð”Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ‹Ðµ: {metadata['cities']}"
            )

        features = preprocess_client(client)

        probability = float(model.predict_proba(features)[0][1])
        prediction = int(probability >= 0.5)

        if probability < 0.3:
            risk_level = "ðŸŸ¢ ÐÐ¸Ð·ÐºÐ¸Ð¹"
        elif probability < 0.7:
            risk_level = "ðŸŸ¡ Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹"
        else:
            risk_level = "ðŸ”´ Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹"

        return PredictionResponse(
            probability=round(probability, 4),
            prediction=prediction,
            risk_level=risk_level
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
